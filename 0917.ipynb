{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian inference for all-nighters problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data model : Binomial\n",
    "#### Prior : discrete\n",
    "\n",
    "#### `목표` : 위의 setting에서 posterior distribution을 구해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install.packages('ggplot2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "priorvalues = c(0, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1)\n",
    "priorprob = c(0, 0, .1, .1, .2, .2, .2, .1, .1, 0, 0)\n",
    "\n",
    "n = 10\n",
    "y = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\operatorname{pr} (p|y) \\propto \\operatorname{pr}(p) \\times \\operatorname{pr}(y; n, p)$\n",
    "\n",
    "> posterior distribution은 사전 확률과 sampling probability의 곱인 joint distribution에 비례한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vector for storing results\n",
    "jointprob = numeric(length = length(priorvalues)) # 0 0 0 0 0 0 0 0 0 0 0\n",
    "for(i in 1:length(priorvalues)) {\n",
    "    #compute binomial probability given value of p\n",
    "    binomprob = dbinom(y, n, p = priorvalues[i])\n",
    "\n",
    "    #compute joint probability\n",
    "    jointprob[i] = binomprob * priorprob[i]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0</li>\n",
       "\t<li>0</li>\n",
       "\t<li>7.86432e-05</li>\n",
       "\t<li>0.000900169199999999</li>\n",
       "\t<li>0.0084934656</li>\n",
       "\t<li>0.0234375</li>\n",
       "\t<li>0.0429981696</li>\n",
       "\t<li>0.0266827932</li>\n",
       "\t<li>0.0201326592</li>\n",
       "\t<li>0</li>\n",
       "\t<li>0</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 7.86432e-05\n",
       "\\item 0.000900169199999999\n",
       "\\item 0.0084934656\n",
       "\\item 0.0234375\n",
       "\\item 0.0429981696\n",
       "\\item 0.0266827932\n",
       "\\item 0.0201326592\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0\n",
       "2. 0\n",
       "3. 7.86432e-05\n",
       "4. 0.000900169199999999\n",
       "5. 0.0084934656\n",
       "6. 0.0234375\n",
       "7. 0.0429981696\n",
       "8. 0.0266827932\n",
       "9. 0.0201326592\n",
       "10. 0\n",
       "11. 0\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 0.0000000000 0.0000000000 0.0000786432 0.0009001692 0.0084934656\n",
       " [6] 0.0234375000 0.0429981696 0.0266827932 0.0201326592 0.0000000000\n",
       "[11] 0.0000000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jointprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\operatorname{pr}(p|y) = \\frac{\\operatorname{pr}(p) \\times \\operatorname{pr}(y; n, p)} {p(y)}$\n",
    "\n",
    "> posterior distribution은 joint distribution에 marginal prob을 나눠주면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute marginal probability of y\n",
    "pofy = sum(jointprob)\n",
    "\n",
    "#compute posterior probabilities\n",
    "posteriorprob = jointprob/pofy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0</li>\n",
       "\t<li>0</li>\n",
       "\t<li>0.000640816665770342</li>\n",
       "\t<li>0.00733494345821578</li>\n",
       "\t<li>0.0692081999031969</li>\n",
       "\t<li>0.190978248646958</li>\n",
       "\t<li>0.350366512009935</li>\n",
       "\t<li>0.217422212878717</li>\n",
       "\t<li>0.164049066437207</li>\n",
       "\t<li>0</li>\n",
       "\t<li>0</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0.000640816665770342\n",
       "\\item 0.00733494345821578\n",
       "\\item 0.0692081999031969\n",
       "\\item 0.190978248646958\n",
       "\\item 0.350366512009935\n",
       "\\item 0.217422212878717\n",
       "\\item 0.164049066437207\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0\n",
       "2. 0\n",
       "3. 0.000640816665770342\n",
       "4. 0.00733494345821578\n",
       "5. 0.0692081999031969\n",
       "6. 0.190978248646958\n",
       "7. 0.350366512009935\n",
       "8. 0.217422212878717\n",
       "9. 0.164049066437207\n",
       "10. 0\n",
       "11. 0\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 0.0000000000 0.0000000000 0.0006408167 0.0073349435 0.0692081999\n",
       " [6] 0.1909782486 0.3503665120 0.2174222129 0.1640490664 0.0000000000\n",
       "[11] 0.0000000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "posteriorprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사전 확률과 사후 확률을 비교하여 우리의 믿음이 어떻게 변했는 지 그리고 싶다.\n",
    "\n",
    "`참고` : ggplot은 tidy한 dataset을 요구하므로 그 형태에 맞춰보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>prior_values</th><th scope=col>probability</th><th scope=col>type</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.0         </td><td>0.0000000000</td><td>prior       </td></tr>\n",
       "\t<tr><td>0.1         </td><td>0.0000000000</td><td>prior       </td></tr>\n",
       "\t<tr><td>0.2         </td><td>0.1000000000</td><td>prior       </td></tr>\n",
       "\t<tr><td>0.3         </td><td>0.1000000000</td><td>prior       </td></tr>\n",
       "\t<tr><td>0.4         </td><td>0.2000000000</td><td>prior       </td></tr>\n",
       "\t<tr><td>0.5         </td><td>0.2000000000</td><td>prior       </td></tr>\n",
       "\t<tr><td>0.6         </td><td>0.2000000000</td><td>prior       </td></tr>\n",
       "\t<tr><td>0.7         </td><td>0.1000000000</td><td>prior       </td></tr>\n",
       "\t<tr><td>0.8         </td><td>0.1000000000</td><td>prior       </td></tr>\n",
       "\t<tr><td>0.9         </td><td>0.0000000000</td><td>prior       </td></tr>\n",
       "\t<tr><td>1.0         </td><td>0.0000000000</td><td>prior       </td></tr>\n",
       "\t<tr><td>0.0         </td><td>0.0000000000</td><td>posterior   </td></tr>\n",
       "\t<tr><td>0.1         </td><td>0.0000000000</td><td>posterior   </td></tr>\n",
       "\t<tr><td>0.2         </td><td>0.0006408167</td><td>posterior   </td></tr>\n",
       "\t<tr><td>0.3         </td><td>0.0073349435</td><td>posterior   </td></tr>\n",
       "\t<tr><td>0.4         </td><td>0.0692081999</td><td>posterior   </td></tr>\n",
       "\t<tr><td>0.5         </td><td>0.1909782486</td><td>posterior   </td></tr>\n",
       "\t<tr><td>0.6         </td><td>0.3503665120</td><td>posterior   </td></tr>\n",
       "\t<tr><td>0.7         </td><td>0.2174222129</td><td>posterior   </td></tr>\n",
       "\t<tr><td>0.8         </td><td>0.1640490664</td><td>posterior   </td></tr>\n",
       "\t<tr><td>0.9         </td><td>0.0000000000</td><td>posterior   </td></tr>\n",
       "\t<tr><td>1.0         </td><td>0.0000000000</td><td>posterior   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " prior\\_values & probability & type\\\\\n",
       "\\hline\n",
       "\t 0.0          & 0.0000000000 & prior       \\\\\n",
       "\t 0.1          & 0.0000000000 & prior       \\\\\n",
       "\t 0.2          & 0.1000000000 & prior       \\\\\n",
       "\t 0.3          & 0.1000000000 & prior       \\\\\n",
       "\t 0.4          & 0.2000000000 & prior       \\\\\n",
       "\t 0.5          & 0.2000000000 & prior       \\\\\n",
       "\t 0.6          & 0.2000000000 & prior       \\\\\n",
       "\t 0.7          & 0.1000000000 & prior       \\\\\n",
       "\t 0.8          & 0.1000000000 & prior       \\\\\n",
       "\t 0.9          & 0.0000000000 & prior       \\\\\n",
       "\t 1.0          & 0.0000000000 & prior       \\\\\n",
       "\t 0.0          & 0.0000000000 & posterior   \\\\\n",
       "\t 0.1          & 0.0000000000 & posterior   \\\\\n",
       "\t 0.2          & 0.0006408167 & posterior   \\\\\n",
       "\t 0.3          & 0.0073349435 & posterior   \\\\\n",
       "\t 0.4          & 0.0692081999 & posterior   \\\\\n",
       "\t 0.5          & 0.1909782486 & posterior   \\\\\n",
       "\t 0.6          & 0.3503665120 & posterior   \\\\\n",
       "\t 0.7          & 0.2174222129 & posterior   \\\\\n",
       "\t 0.8          & 0.1640490664 & posterior   \\\\\n",
       "\t 0.9          & 0.0000000000 & posterior   \\\\\n",
       "\t 1.0          & 0.0000000000 & posterior   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| prior_values | probability | type |\n",
       "|---|---|---|\n",
       "| 0.0          | 0.0000000000 | prior        |\n",
       "| 0.1          | 0.0000000000 | prior        |\n",
       "| 0.2          | 0.1000000000 | prior        |\n",
       "| 0.3          | 0.1000000000 | prior        |\n",
       "| 0.4          | 0.2000000000 | prior        |\n",
       "| 0.5          | 0.2000000000 | prior        |\n",
       "| 0.6          | 0.2000000000 | prior        |\n",
       "| 0.7          | 0.1000000000 | prior        |\n",
       "| 0.8          | 0.1000000000 | prior        |\n",
       "| 0.9          | 0.0000000000 | prior        |\n",
       "| 1.0          | 0.0000000000 | prior        |\n",
       "| 0.0          | 0.0000000000 | posterior    |\n",
       "| 0.1          | 0.0000000000 | posterior    |\n",
       "| 0.2          | 0.0006408167 | posterior    |\n",
       "| 0.3          | 0.0073349435 | posterior    |\n",
       "| 0.4          | 0.0692081999 | posterior    |\n",
       "| 0.5          | 0.1909782486 | posterior    |\n",
       "| 0.6          | 0.3503665120 | posterior    |\n",
       "| 0.7          | 0.2174222129 | posterior    |\n",
       "| 0.8          | 0.1640490664 | posterior    |\n",
       "| 0.9          | 0.0000000000 | posterior    |\n",
       "| 1.0          | 0.0000000000 | posterior    |\n",
       "\n"
      ],
      "text/plain": [
       "   prior_values probability  type     \n",
       "1  0.0          0.0000000000 prior    \n",
       "2  0.1          0.0000000000 prior    \n",
       "3  0.2          0.1000000000 prior    \n",
       "4  0.3          0.1000000000 prior    \n",
       "5  0.4          0.2000000000 prior    \n",
       "6  0.5          0.2000000000 prior    \n",
       "7  0.6          0.2000000000 prior    \n",
       "8  0.7          0.1000000000 prior    \n",
       "9  0.8          0.1000000000 prior    \n",
       "10 0.9          0.0000000000 prior    \n",
       "11 1.0          0.0000000000 prior    \n",
       "12 0.0          0.0000000000 posterior\n",
       "13 0.1          0.0000000000 posterior\n",
       "14 0.2          0.0006408167 posterior\n",
       "15 0.3          0.0073349435 posterior\n",
       "16 0.4          0.0692081999 posterior\n",
       "17 0.5          0.1909782486 posterior\n",
       "18 0.6          0.3503665120 posterior\n",
       "19 0.7          0.2174222129 posterior\n",
       "20 0.8          0.1640490664 posterior\n",
       "21 0.9          0.0000000000 posterior\n",
       "22 1.0          0.0000000000 posterior"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#put posterior probabilities in one matrix object for visualization\n",
    "allnighterposterior = data.frame(prior_values=rep(priorvalues, 2), \n",
    "                                 probability=c(priorprob, posteriorprob))\n",
    "allnighterposterior$type = factor(c(rep('prior', 11), rep('posterior', 11)), \n",
    "                                  levels=c('prior', 'posterior'))\n",
    "allnighterposterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAS1BMVEUAAAAzMzNNTU1oaGh1\n1dd52Nt8fHx/3+GMjIyampqnp6eysrK9vb3Hx8fQ0NDZ2dnh4eHp6enr6+vw8PDysKzy8vL1\ntK/7urb////G35AlAAAACXBIWXMAABJ0AAASdAHeZh94AAAgAElEQVR4nO3d60Jct5KA0T7t\nGWLjxBd5ZsL7P+nQjREN3oUlENolvL4fDvhQckWwTnMzOdxIenWHvReQ3kMgSQMCSRoQSNKA\nQJIGBJI0IJCkAYEkDeg1kMpLetlUthMssfcSwwQMCiRL7H0ESNNuLd0Jlth7iWECBgWSJfY+\nAqRpt5buBEvsvcQwAYMCyRJ7HwHStFtLd4Il9l5imIBBgWSJvY8AadqtpTvBEnsvMUzAoECy\nxN5HgDTt1tKdYIm9lxgmYFAgWWLvI0CadmvpTrDE3ksMEzAokCyx9xEgTbu1dCdYYu8lhgkY\nFEiW2PsIkKbdWroTLLH3EsMEDAokS+x9BEjTbi3dCZbYe4lhAgYFkiX2PgKkabeW7gRL7L3E\nMAGDAskSex8B0rRbS3eCJfZeYpiAQYFkib2PAGnaraU7wRJ7LzFMwKBAssTeR4A07dbSnWCJ\nvZcYJmBQIFli7yNAmnZr6U6wxN5LDBMwKJAssfcRIE27tXQnWGLvJYYJGBRIltj7CJCm3Vq6\nEyyx9xLDBAwKJEvsfQRI024t3QmW2HuJYQIGBdJSS/zXo/6qT01dYvQRfzwkTe+voL33kkek\npZbwiFSHkgXSUkuAVIeSBdJSS4BUh5IF0lJLgFSHkgXSUkuAVIeSBdJSS4BUh5IF0lJLgFSH\nkgXSUkuAVIeSBdJSS4BUh5IF0lJLgFSHkgXSUkuAVIeSBdJSS4BUh5IF0lJLgFSHkgXSUkuA\nVIeSBdJSS4BUh5IF0lJLgFSHkgXSUkuAVIeSBdJSS4BUh5IF0lJLgFSHkgXSUkuAVIeSBdJS\nS4BUh5IF0lJLgFSHkgXSUkuAVIeSBdJSS4BUh5IF0lJLgFSHkgXSUkuAVIeSBdJSS4BUh5IF\n0lJLgFSHkgXSUkuAVIeSBdJSS4BUh5IF0lJLgFSHkgXSUkuAVIeSBdJSS4BUh5IF0lJLgFSH\nkgXSUkuAVIeSBdJSS4BUh5IF0lJLgFSHkgXSUkuAVIeSBdJSS4BUh5IF0lJLgFSHkgXSUkuA\nVIeSBdJSS4BUh5IF0lJLgFSHkgXSUkuAVIeSBdJSS4BUh5IF0lJLgFSHkgXSUkuAVIeSBdJS\nS4BUh5IF0lJLgFSHkgXSUkuAVIeSBdJSS4BUh5IF0lJLgFSHkgXSUkuAVIeSBdJSS4BUh5IF\n0lJLgFSHkgXSUkuAVIeSBdJSS4BUh5IF0lJLgFSHkgXSUkuAVIeSBdJSS4BUh5IF0lJLgFSH\nkgXSUkuAVIeSBdJSS4BUh5IF0lJLgFSHkgXSUkuAVIeSBdJSS4BUh5IF0lJLgFSHkgXSUkuA\nVIeSBdJSS4BUh5IF0lJLgFSHkgXSUkuAVIeSBdJSS4BUh5IF0lJLgFSHkgXSUkuAVIeSBdJS\nS4BUh5IF0lJLgFSHkgXSUkuAVIeSBdJSS4BUh5IF0lJLgFSHkgXSUkuAVIeSBdJSS4BUh5IF\n0lJLgFSHkgXSUkuAVIeSBdJSS4BUh5IF0lJLgFSHkgXSUkuAVIeSBdJSS4BUh5IF0lJLgFSH\nkgXSUkuAVIeSBdJSS4BUh5IF0lJLgFSHkgXSUkuAVIeSBdJSS4BUh5IF0lJLgFSHkgXSUkuA\nVIeS9XtIx9u2ngZphxNAqkPJ+i2kY/3l8dM3IO1wAkh1KFkgLbUESHUoWV2Qbh4/Pe/W0p0A\n0sAj/mRI/zn1Risp7q+gvfdSJySfbNh3CY9IdShZ3rVbagmQ6lCyQFpqCZDqULJ81m6pJUCq\nQ8kCaaklQKpDyWr/zobjxdN3zbu1dCeANPCIPwRS3LxbS3cCSAOPAGnaraU7AaSBR4A07dbS\nnQDSwCNAmnZr6U4AaeARIE27tXQngDTwCJCm3Vq6E0AaeARI024t3QkgDTwCpGm3lu4EkAYe\nAdK0W0t3AkgDjwBp2q2lOwGkgUeANO3W0p0A0sAjQJp2a+lOAGngESBNu7V0J4A08AiQpt1a\nuhNAGngESNNuLd0JIA08AqRpt5buBJAGHgHStFtLdwJIA48AadqtpTsBpIFHgDTt1tKdANLA\nI0CadmvpTgBp4BEgTbu1dCeANPAIkKbdWroTQBp4BEjTbi3dCSANPAKkabeW7gSQBh4B0rRb\nS3cCSAOPAGnaraU7AaSBR4A07dbSnQDSwCNAmnZr6U4AaeARIE27tXQngDTwCJCm3Vq6E0Aa\neARI024t3QkgDTwCpGm3lu4EkAYeAdK0W0t3AkgDjwBp2q2lOwGkgUeANO3W0p0A0sAjQJp2\na+lOAGngESBNu7V0J4A08AiQpt1auhNAGngESNNuLd0JIA08AqRpt5buBJAGHgHStFtLdwJI\nA48AadqtpTsBpIFHgDTt1tKdANLAI0CadmvpTgBp4BEgTbu1dCeANPAIkKbdWroTQBp4BEjT\nbi3dCSANPAKkabeW7gSQBh4B0rRbS3cCSAOPAGnaraU7AaSBR4A07dbSnQDSwCNAmnZr6U4A\naeARIE27tXQngDTwCJCm3Vq6E0AaeARI024t3QkgDTwCpGm3lu4EkAYeAdK0W0t3AkgDjwBp\n2q2lOwGkgUeANO3W0p0A0sAjQJp2a+lOAGngESBNu7V0J4A08AiQpt1auhNAGngESNNuLd0J\nIA08AqRpt5buBJAGHgHStFtLdwJIA48AadqtpTsBpIFHgDTt1tKdANLAI0CadmvpTgBp4BEg\nTbu1dCeANPAIkKbdWroTQBp4BEjTbi3dCSANPAKkabeW7gSQBh4B0rRbS3cCSAOPAGnaraU7\nAaSBR4A07dbSnQDSwCNAmnZr6U4AaeARIE27tXQngDTwCJCm3Vq6E0AaeARI024t3QkgDTwC\npGm3lu4EkAYeAdK0W0t3AkgDjwBp2q2lOwGkgUeANO3W0p0A0sAjQJp2a+lOAGngESBNu7V0\nJ4A08AiQpt1auhNAGngESNNuLd0JIA08AqRpt5buBJAGHgHStFtLdwJIA48AadqtpTsBpIFH\ngDTt1tKdANLAI0CadmvpTgBp4BEgTbu1dCeANPAIkKbdWroTQBp4xB8PSdP7K2jvveQRaakl\nPCLVoWSBtNQSINWhZIG01BIg1aFkgbTUEiDVoWSBtNQSINWhZIG01BIg1aFkgbTUEiDVoWSB\ntNQSINWhZIG01BIg1aFkgbTUEiDVoWSBtNQSINWhZIG01BIg1aFkgbTUEiDVoWSBtNQSINWh\nZIG01BIg1aFkgbTUEiDVoWSBtNQSINWhZIG01BIg1aFkgbTUEiDVoWSBtNQSINWhZIG01BIg\n1aFkgbTUEiDVoWSBtNQSINWhZIG01BIg1aFkgbTUEiDVoWSBtNQSINWhZIG01BIg1aFkgbTU\nEiDVoWSBtNQSINWhZIG01BIg1aFkgbTUEiDVoWSBtNQSINWhZIG01BIg1aFkgbTUEiDVoWSB\ntNQSINWhZIG01BIg1aFkgbTUEiDVoWSBtNQSINWhZIG01BIg1aFkgbTUEiDVoWSBtNQSINWh\nZIG01BIg1aFkgbTUEiDVoWSBtNQSINWhZIG01BIg1aFkgbTUEiDVoWSBtNQSINWhZIG01BIg\n1aFkgbTUEiDVoWSBtNQSINWhZIG01BIg1aFkgbTUEiDVoWSBtNQSINWhZIG01BIg1aFkgbTU\nEiDVoWSBtNQSINWhZIG01BIg1aFkgbTUEiDVoWSBtNQSINWhZIG01BIg1aFkgbTUEiDVoWSB\ntNQSINWhZIG01BIg1aFkgbTUEiDVoWSBtNQSINWhZIG01BIvg/RfQSvfxDABgwJpqSVAqkPJ\nAmmpJUCqQ8kCaaklQKpDyQJpqSVAqkPJAmmpJUCqQ8kCaaklQKpDyQJpqSVAqkPJAmmpJUCq\nQ8kCaaklQKpDyQJpqSVAqkPJAmmpJUCqQ8kCaaklQKpDyQJpqSVAqkPJAmmpJUCqQ8kCaakl\nQKpDyQJpqSVAqkPJAmmpJUCqQ8kCaaklQKpDyQJpqSVAqkPJAmmpJUCqQ8kCaaklQKpDyQJp\nqSVAqkPJAmmpJUCqQ8kCaaklQKpDyQJpqSVAqkPJAmmpJUCqQ8kCaaklQKpDyQJpqSVAqkPJ\nAmmpJUCqQ8kCaaklQKpDyfo9pONtW0+DtMMJINWhZP0W0rH+8vjpG5B2OAGkOpQskJZaAqQ6\nlKwuSDePn553a+lOAKkG0rkXQvrPqTdaKW//Bo0fiqb+Cnr+sJdNqaduSH/yJxv+56F/L57+\nn9ahRz2/RDDkEakOJQukjkDaCKRzvZAu38mbd2tJTgBpI5DOdUK6dAQSSAWkn/VBeuQIJJAK\nSD9r/86G492Txz/4098gbQTSOd9r1xFIG4F0DqSOQNoIpHNPIH34/LV9dt6tJTkBpI1AOvcE\n0uFwOH760jg779aSnADSRiCdewLpxz8fby0drv753jA779aSnADSRgkh/X187n99mzY+Rvpy\nfby19OH3j0vzbi3JCSBtlBDS4TUf+b+wrT/y+/Xh/LD0u9l5t5bkBJA2Aunuz/zld759PD8c\nfb06fPzN7LxbS3ICSBvlg3R6FPhx+HB68vSPW1YfD1fnj1V+fDocPv14MZbnegrpy1V9r+63\nrufdWpITQNooJ6Sb68Pprfifw+fbZz+dPod28nP6mOVO2PCefvr7cPj47f5/+t2HbPNuLckJ\nIG2UD9L5IeDb+UOTj4evt89d/bi5Olzf3Hw+/XJ9+PvFWp77M588e/1t++W2mndrSU4AaaOk\nkG4Nfbt7MDicnvh+eiD6cH5r/+2HLC/q6ae/e2bn3VqSE4ZC+it8635mCqQ69Nwb9emt+tst\nmC+HT/cfopx+Pfys00hTv3xB9u6fx5bPxM+7tSQngLRRVki3jz/fzx8ozYd0PFzUMDvv1pKc\nANJGaSF9OVwfD+fnvp/etbu6f9fubbo8+u8LRy0fkM27tSQngLRRWkinz5xdnZ+7uvlxdfh8\n+jzD9ekTeb/9AulLCt61a2rerSU5AaSNUkI6f2Ty5XD45/zc1eHud37cvc/V8fm09vw1io5A\n2ighpL9/fuXm/E7d6derw6fzF2S/f7pV1fH3Gzq6hHT7cORjpOcCaaOEkH729e5rr3O+YQik\njkDaKC+kq/M3N+wAqbd5t5bkBJA2ygqpfts1SOlOAGmjrJCO99/BsMe7dr6O9GwgbZQV0uRA\n6gikjUA65127jkDaCKRzIHUE0kYgnfPp745A2gikcyB1BNJGIJ3zrl1HIG0E0jmQOgJpI5DO\nPYX04/rD4fDhc9PflJ13a0lOAGmjhJD+L+5/XyzlNz2B9P3nX+47+kmrG4G0EUjnnkC6Ov8A\nsO+//5l2p+bdWpITQNoIpHPbf7Hvh8/abQXSRiCdewLm4+HuoyOPSFuBtBFI554+8ny8e9eu\n6Ud/zbu1JCeAtBFI53zTakcgbQTSOZA6AmkjkM75gmxHIG0E0jmQOgJpo/cB6dV/i/bpAdfe\ntYsDaaP3AenVPQFz7WOkZwJpI5DOPQFzPHy7Onz/cXVo+Sl6824tyQkgbbQspPNfGvr5z5u7\nHxL+8Hx3v35nw+fDl5sfTT8fed6tJTkBpI3WhXSn5uGfNxfPd/crpC+nH6DvXbutQNpoXUg/\nf9n8Z3e/fIvQP6f/ttlXkLYCaSOQHk576CTo9LP7T/+ls98279aSnADSRiA9nHbRlw83N58O\np/+OzO+bd2tJTgBpI5AeTnth824tyQkgbbQupKefZLj8Z3cgdQTSRutCqp/+/vnL4eL57vzM\nho5A2mhhSCPzMxs6AmkjkLZO8zMbngukjUDaOs3PbHgukDZaFtLY/MyGjkDaCKRzfmZDRyBt\nBNI5f9W8I5A2Sgjpf5/pdVziQOoIpI1AOucLsh2BtFFCSHsEUkcgbZQQ0n/HTXtEuvvOhmvf\n2bAVSBuBdM53NnQE0kYgnXsC6dP9dzb4+0gbgbQRSOe2v7PBXzXfDKSNQDoHUkcgbQTSOe/a\ndQTSRiCd88mGjv4oSPHQ40A659PfHYEEUpQvyHYE0h8JqcnI07/Y1/Kx0X3zbi3JCSD9CZCG\n/MyGY88p824tyQkggdQ49e3quuXTDHfNu7UkJ4D0niDd/xSh+58e9POfl792/ID9X76O5K9R\nxIH0riA983PtHv1A/aYfsA9SRyC9K0gbgO5/v/+nsPqsXUcgvWdI9w839+/JHUB6qxNAeteQ\nHt6Te/To9DJI5y/IXn0GaSuQ3jmkxx8jvQaSbxF6LpDeFaSWTza8FNKVb1p9JpDeFaTtT3/f\nPP70983DB02/cokh+UmrzwXS+4I0sien1Z+06j/GvBFIIEU9Pe3T1bfTu3ZXPkbaCCSQosIv\nyDZ8UXberSU5AaT3BGlsIHUEEkhRviDbEUggRYHUEUhrQPKzv5OfANIakPYIpI5AAikKpI5A\nAikKpI5AAikKpI5AAikKpI5AAikKpI5AAikKpI5AAilq7HfuvfP+DXrR0F9Bz049PxT1oqmX\n/VF/bB6ROvKI5BEpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIp\nCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIp\nCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIp\nCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIp\nCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIp\nCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIp\nCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIp\nCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIp\nCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIp\nCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIp\nCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIpCqSOQAIp6veQjrddPHfxv8y7\ntSQngARS1G8hHesv5ydAAulxIJ3rg3T0iATSk0A61/mIBBJITwLp3Ash/efUG63U279ByYf+\nCnp26kVDz0+9bD896R08IkX/l//sCf1DJf8jUvRHPfuI1D/0/Kujvz/5EencvFt79oR+EyCB\nNDqQWocKSCDFgdQ6VEACKQ6k1qECEkhx7d/ZcEcIpLtAil4d/f0hkOLm3dqzJ/SbAAmk0YHU\nOlRAAikOpNahAhJIcSC1DhWQQIoDqXWogARSHEitQwUkkOJAah0qIIEUB1LrUAEJpDiQWocK\nSCDFgdQ6VEACKQ6k1qECEkhxILUOFZBAigOpdaiABFIcSK1DBSSQ4kBqHSoggRQHUutQAQmk\nOJBahwpIIMWB1DpUQAIpDqTWoQISSHEgtQ4VkECKA6l1qIAEUhxIrUMFJJDiQGodKiCBFAdS\n61ABCaQ4kFqHCkggxYHUOlRAAikOpNahAhJIcSC1DhWQQIoDqXWogARSHEitQwUkkOJAah0q\nIIEUB1LrUAEJpDiQWocKSCDFgdQ6VEACKQ6k1qECEkhxILUOFZBAigOpdaiABFIcSK1DBSSQ\n4kBqHSoggRQHUutQAQmkOJBahwpIIMWB1DpUQAIpDqTWoQISSHEgtQ4VkECKA6l1qIAEUhxI\nrUMFJJDiQGodKiCBFAdS61ABCaQ4kFqHCkggxYHUOlRAAikOpNahAhJIcSC1DhWQQIoDqXWo\ngARSHEitQwUkkOJAah0qIIEUB1LrUIkhPfs2F/1JIL3qhGECBgVS61ABCaQ4kFqHCkggxYHU\nOlRAAikOpNahAhJIcSC1DhWQQIoDqXWogARSHEitQwUkkOJAah0qIIEUB1LrUAEJpDiQWocK\nSCDFgdQ6VEACKQ6k1qECEkhxILUOFZBAigOpdaiABFIcSK1DBSSQ4kBqHSoggRQHUutQAQmk\nOJBahwpIIMWB1DpUQAIpDqTWoQISSHEgtQ4VkECKA6l1qIAEUhxIrUMFJJDiQGodKiCBFAdS\n61ABCaQ4kFqHCkggxYHUOlRAAikOpNahAhJIcSC1DhWQQIoDqXWogARSHEitQwUkkOJAah0q\nIIEUB1LrUAEJpDiQWocKSCDFgdQ6VEACKQ6k1qECEkhxILUOFZBAigOpdaiABFLcayAl6d+g\neUN/Bb18KJp60dBb7KcneURqHSoekTwixYHUOlRAAikOpNahAhJIcSC1DhWQQIoDqXWogARS\nHEitQwUkkOJAah0qIIEUB1LrUAEJpDiQWocKSCDFgdQ6VEACKQ6k1qECEkhxILUOFZBAigOp\ndaiABFIcSK1DBSSQ4kBqHSoggRQHUutQAQmkOJBahwpIIMWB1DpUQAIpDqTWoQISSHEgtQ4V\nkECKA6l1qIAEUhxIrUMFJJDiQGodKiCBFAdS61ABCaQ4kFqHCkggxYHUOlRAAikOpNahAhJI\ncSC1DhWQQIoDqXWogARSHEitQwUkkOJAah0qIIEUB1LrUAEJpDiQWocKSCDFgdQ6VEACKQ6k\n1qECEkhxILUOFZBAigOpdaiABFIcSK1DBSSQ4kBqHSoggRQHUutQAQmkOJBahwpIIMWB1DpU\nQAIpDqTWoQISSHEgtQ4VkECKA6l1qIAEUhxIrUMFJJDiQGodKiCBFAdS61ABCaQ4kFqHCkgg\nxYHUOlRAAikOpNahAhJIcSC1DhWQQIoDqXWogARSHEitQwUkkOJAah0qIIEUB1LrUAEJpDiQ\nWocKSCDFgdQ6VEACKQ6k1qECEkhxILUOFZBAigOpdaiABFIcSK1DBSSQ4kBqHSoggRQHUutQ\nAQmkOJBahwpIIMWB1DpUQAIpDqTWoQISSHEgtQ4VkECKA6l1qIAEUhxIrUMFJJDiQGodKiCB\nFAdS61ABCaQ4kFqHCkggxYHUOlRAAikOpNahAhJIcSC1DhWQQIoDqXWogARSHEitQwUkkOJA\nah0qIIEUB1LrUAEJpDiQWocKSCDFgdQ6VEACKQ6k1qECEkhxILUOFZBAigOpdaiABFIcSB1v\nPhcvB9LbvULbhpIFUsebz8XLgfR2r9C2oWSB1PHmc/FyIL3dK7RtKFkgdbz5XLwcSG/3Cm0b\nShZIHW8+Fy8H0tu9QtuGkgVSx5vPxcuB9Hav0LahZIHU8eZz8XIgvd0rtG0oWSB1vPlcvBxI\nb/cKbRtKFkgdbz4XLwfS271C24aSBVLHm8/Fy4H0dq/QtqFkgdTx5nPxciC93Su0bShZv4d0\nvG3raZC6hx4F0qtOeBMNr+i3kI71l8dP34DUPfQokF51wptoeEXvGNL4N5+LlwPp7V6hbUPJ\nAqnjzefi5UB6u1do21CyXgjpP6febitpsd7BI9IeJ1hi7yXeRMMrAskSex8B0rRbS3eCJfZe\n4k00vCKQLLH3ESBNu7V0J1hi7yXeRMMrav/OhuPF03fNu7V0J1hi7yXeCsRLewffa7fHCZbY\ne4lhAgYFkiX2PgKkabeW7gRL7L3EMAGDAskSex8B0rRbS3eCJfZeYpiAQYFkib2PAGnaraU7\nwRJ7LzFMwKBAssTeR4A07dbSnWCJvZcYJmBQIFli7yNAmnZr6U6wxN5LDBMwKJAssfcRIE27\ntXQnWGLvJYYJGBRIltj7CJCm3Vq6Eyyx9xLDBAwKJEvsfQRI024t3QmW2HuJYQIGBZIl9j4C\npGm3lu4ES+y9xDABgwLJEnsfAdK0W0t3giX2XmKYgEGBZIm9jwBp2q2lO8ESey8xTMCgQLLE\n3keANO3W0p1gib2XGCZgUCBZYu8jQJp2a+lOsMTeSwwTMCiQLLH3EX88pBeV4T+YmWEHS9RS\nLPHaQNorS9yXYonXBtJeWeK+FEu8NpD2yhL3pVjitU2HJL3HQJIGBJI0IJCkAYEkDQgkaUBT\nIB1ve/r05e/tucOuSxxv5l/E5R94vFxi7hY3D3/cXm8SQ5sB6Vh/eXj68vdmtLXDzD//lyV+\nWWaXJe6fnv8GfPH/KD9/mX4TQwNpYikh7fP2e7wBqbtskO5/Y4e3npvHF3GTBNIeb74gdZcW\n0vQPkS6WqB+dPF1s5hL12R0+PAGpu4yQdn8b3u3NZxPS7CVuQHpBGd5+Nj8ymLxD/P7l3pCe\nPDVvj/oESA0lhLTPm09CSFv/3zJxj/oESA3lg3Tc+L3JSyR5126nm/hlBZAayvD28+jPu9hl\nv082XC6QAdLsN2GQ+qtfur58eqdvKjjePP56/swdUlzEoyUq670+a7frTYzM99pJAwJJGhBI\n0oBAkgYEkjQgkKQBgSQNCCRpQCBJAwLprTr0Xm33gBLllfdWgfRH5ZWXJpBWzitvVLcOPh6u\nvp+f+na8unPx/dPh8Onh9+77cfhw/ueHw7ebrx8Ph+P13QE/MZ1//XEa/XF69vPx8OHvyf82\n6gykUd2+2R9uSfw4PXV1+HTW8ON4ePR7tY+Hk67vt56+HM5d/wLpPHrydn1+AZJyB9Kobqn8\nuLm6E3H/AHN9uH0Uuvi92pfzs9eHL7cPSv/c3Hy7R/QA6fPpJa5Pfg636L4e1v0LBn9GII3q\n9p23u8eY81v+nYYPp6cufu+hD3d/Eef05Pcvn69+hfTh7qmPp4emT18m/7uoO5BG9WAgfuqh\nvw9fbx9mPt+cHrDO/Tpw//tfbt/J+/CYodIF0qj6IP24/Yjp+nD7wdOnw4e/v3x/DtLte34f\nDsevM/9d1B1IozrcvRt39fj9s4d37Z68+IQmFOEAAADsSURBVKfD99P7bT8/Q/cI0veHd+3u\n+9vnxpPn9TOqw62hH1en99YeIF1+suHJi3+9fbT5en6xr6exn4iOh39+Pnd9mvrnNH+8fYlv\nPtmQPJBGdfoE9+H89v4A6fLT309f/sPd15KuD5cfI52f+/wwevoExt1LfJ78r6O+QBrV7bt2\nV/dffL25//XiC7JPX/7v0+e9b07v4x2uvtZ3666Pt2Tq6NX5I6Pb3ztylDyQRuWjmD86r/1R\ngfRH57U/qgZIh8PlJ7X1nvIqHRVIf3RepdKAQJIGBJI0IJCkAYEkDQgkaUAgSQMCSRrQ/wMd\n5GOLx+0OmgAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(ggplot2)\n",
    "ggplot(data=allnighterposterior, aes(x=prior_values, y=probability, fill=type)) + \n",
    "    geom_bar(stat='identity', alpha=0.5, position='dodge')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
